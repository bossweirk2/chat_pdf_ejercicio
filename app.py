import os
import streamlit as st
from PIL import Image
from PyPDF2 import PdfReader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.llms import OpenAI
from langchain.chains.question_answering import load_qa_chain
import platform

# --- CONFIGURACI√ìN DE P√ÅGINA ---
st.set_page_config(page_title="Asistente Repostero", page_icon="üç∞", layout="wide")

# --- T√çTULO Y DESCRIPCI√ìN ---
st.markdown("""
# üç∞ Asistente Repostero: An√°lisis de Recetas y T√©cnicas
Bienvenido al **Asistente Repostero**, tu ayudante experto para entender, analizar y dominar cualquier texto sobre pasteler√≠a, t√©cnicas de postres o recetas.  
Sube un PDF con recetas o teor√≠a y hazle preguntas al estilo de un chef pastelero profesional.  
""")

st.caption(f"Versi√≥n de Python: {platform.python_version()}")

# --- IMAGEN DE PRESENTACI√ìN ---
try:
    image = Image.open('Chat_pdf.png')
    st.image(image, width=350)
except Exception as e:
    st.warning(f"No se pudo cargar la imagen: {e}")

# --- SIDEBAR ---
with st.sidebar:
    st.header("ü•Ñ Panel del Chef Repostero")
    st.info("Aqu√≠ podr√°s subir tu documento y conversar sobre sus contenidos como si hablaras con un maestro pastelero.")
    st.markdown("**Consejo:** Puedes subir gu√≠as, recetarios o material t√©cnico sobre postres y pedir an√°lisis espec√≠ficos.")

# --- API KEY ---
ke = st.text_input('üîë Ingresa tu Clave de OpenAI', type="password")
if ke:
    os.environ['OPENAI_API_KEY'] = ke
else:
    st.warning("Por favor ingresa tu clave de API de OpenAI para continuar")

# --- CARGA DEL PDF ---
pdf = st.file_uploader("üìÑ Carga tu archivo PDF de postres o recetas", type="pdf")

# --- PROCESAMIENTO DEL PDF ---
if pdf is not None and ke:
    try:
        # Extraer texto
        pdf_reader = PdfReader(pdf)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text()
        
        st.success(f"Texto extra√≠do correctamente. Total de {len(text)} caracteres.")
        
        # Dividir en fragmentos
        text_splitter = CharacterTextSplitter(
            separator="\n",
            chunk_size=500,
            chunk_overlap=20,
            length_function=len
        )
        chunks = text_splitter.split_text(text)
        st.info(f"Documento dividido en {len(chunks)} fragmentos de conocimiento repostero.")

        # Crear base de conocimiento
        embeddings = OpenAIEmbeddings()
        knowledge_base = FAISS.from_texts(chunks, embeddings)

        # --- SECCI√ìN DE PREGUNTAS RECOMENDADAS ---
        st.subheader("üçÆ Preguntas recomendadas")
        st.markdown("Selecciona alguna o escribe la tuya propia:")

        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("¬øQu√© t√©cnicas se usan para lograr una textura esponjosa?"):
                user_question = "¬øQu√© t√©cnicas se usan para lograr una textura esponjosa en los postres?"
            elif st.button("¬øC√≥mo equilibrar dulzura y acidez?"):
                user_question = "¬øC√≥mo se puede equilibrar la dulzura y acidez en un postre?"
            else:
                user_question = None
        with col2:
            if st.button("Errores comunes en masas o cremas"):
                user_question = "¬øCu√°les son los errores m√°s comunes al preparar masas o cremas?"
        with col3:
            if st.button("Principios de la decoraci√≥n moderna"):
                user_question = "¬øCu√°les son los principios de la decoraci√≥n moderna en pasteler√≠a?"

        # Campo para pregunta personalizada
        user_custom_question = st.text_area("O escribe tu pregunta:", placeholder="Ejemplo: ¬øQu√© temperatura ideal se usa para hornear un souffl√©?")
        if user_custom_question.strip():
            user_question = user_custom_question

        # --- RESPUESTA ---
        if user_question:
            docs = knowledge_base.similarity_search(user_question)
            llm = OpenAI(temperature=0, model_name="gpt-4o")
            chain = load_qa_chain(llm, chain_type="stuff")
            response = chain.run(input_documents=docs, question=user_question)

            st.markdown("### üßÅ Respuesta del Chef Repostero:")
            st.markdown(response)

    except Exception as e:
        st.error(f"Error al procesar el PDF: {str(e)}")
        import traceback
        st.error(traceback.format_exc())

elif pdf is not None and not ke:
    st.warning("Por favor ingresa tu clave de API de OpenAI para continuar.")
else:
    st.info("üìö Carga un PDF de recetas o teor√≠a repostera para comenzar tu an√°lisis dulce.")

